\documentclass[specialist, subf, href, colorlinks=true, 12pt, times, mtpro, final]{disser}
\usepackage [russian] {babel}
\usepackage [utf8] {inputenc}
\usepackage {amsmath}
\usepackage {amsthm}
\usepackage {amssymb}
\usepackage{wrapfig}
\usepackage{enumitem}
\usepackage{amsfonts}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{algorithm}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{pdfpages}

\theoremstyle{definition}
\newtheorem{defn}{Определение}[section]
\newtheorem{example}{Пример}[section]
\newtheorem{state}{Утверждение}[section]

\definecolor{linkcolor}{HTML}{0000FF}
\definecolor{urlcolor}{HTML}{0000FF}
\hypersetup{pdfstartview = FitH, linkcolor = linkcolor, urlcolor = urlcolor, colorlinks = true}

\begin{document}

\tableofcontents

\section* {Вопросы}
\begin{center}
    Вопросы по курсу <<Численные методы>> \\ 4 курс, II поток
\end{center}
{\small
\noindent 1. Погрешность метода и вычислительная погрешность. Пример неустойчивого алгоритма.\\
\noindent 2. Алгебраическая интерполяция. Многочлен Лагранжа.\\
\noindent 3. Константа Лебега интерполяционного процесса для равноотстоящих узлов.\\
\noindent 4. Многочлены Чебышёва и их свойства.\\
\noindent 5. Интерполяционные сплайны. Конструкция и обоснование кубического сплайна.\\
\noindent 6. Понятие об аппроксимационных сплайнах.\\
\noindent 7. Наилучшее приближение в линейном нормированном пространстве.\\
\noindent 8. Наилучшее приближение в гильбертовом пространстве.\\
\noindent 9. Дискретное преобразование Фурье. Идея быстрого дискретного преобразования Фурье.\\
\noindent 10. Наилучшее равномерное приближение многочленами.\\
\noindent 11. Квадратурные формулы интерполяционного типа.\\
\noindent 12. Ортотональные многочлены и квадратуры Гаусса.\\
\noindent 13. Составные квадратурные формулы. Правило Рунге для оценки погрешности.\\
\noindent 14. Основные приёмы для вычисления нерегулярных интегралов.\\
\noindent 15. Метод прогонки для решения трёхдиагональных систем. Корректность и устойчивость метода прогонки.\\
\noindent 16. Прямые методы решения систем линейных уравнений. Методы Гаусса и Холецкого.\\
\noindent 17. Прямые методы решения систем линейных уравнений. Методы отражений и вращений.\\
\noindent 18. Число обусловленности. Неравенства для ошибки и невязки.\\
\noindent 19. Метод простой итерации решения систем линейных уравнений.\\
\noindent 20. Оптимальный одношаговый итерационный метод.\\
\noindent 21. Оптимальный циклический итерационный метод.\\
\noindent 22. Обобщённый метод простой итерации.\\
\noindent 23. Методы Якоби и Гаусса -- Зейделя.\\
\noindent 24. Метод верхней релаксации.\\
\noindent 25. Метод наискорейшего градиентного спуска.\\
\noindent 26. Линейная задача наименьших квадратов. Метод нормального уравнения.\\
\noindent 27. Линейная задача наименьших квадратов. Методы QR-разложения и сингулярного разложения.\\
\noindent 28. Общая идея и примеры проекционных методов.\\
\noindent 29. Пространства Крылова. Понятие о методе сопряженных градиентов.\\
\noindent 30. Частичная проблема собственных значений.\\
\noindent 31. Полная проблема собственных значений. QR-алгоритм.\\
\noindent 32. Метод простой итерации для нелинейных уравнений.\\
\noindent 33. Метод Ньютона.\\
\noindent 34. Явный метод Эйлера для обыкновенных дифференциальных уравнений (ОДУ). Устойчивость. Локальная и глобальная ошибки.\\
\noindent 35. Явные методы Рунге -- Кутты.\\
\noindent 36. Неявные одношаговые методы решения ОДУ.\\
\noindent 37. Многошаговые методы решения ОДУ.\\
\noindent 38. Основы метода конечных элементов: вариационная постановка задачи, метод Ритца, базисные функции.\\
\noindent 39. Оценка точности приближения кусочно -- линейными функциями.\\
\noindent 40. Проекционная теорема в методе конечных элементов.\\
\noindent 41. Система уравнений в методе конечных элементов.\\
\noindent 42. Решение модельной задачи методом Фурье.\\
\noindent 43. Исследование устойчивости модельной задачи методом Фурье.\\
\noindent 44. Метод стрельбы для решения трехдиагональных систем.\\
\noindent 45. Пример аппроксимации уравнения и краевых условий.\\
\noindent 46. Определения аппроксимации и устойчивости.\\
\noindent 47. Определение сходимости. Теорема А.Ф.Филиппова.\\
\noindent 48. Интегро -- интерполяционный метод.\\
\noindent 49. Исследование устойчивости методом априорных оценок.\\
\noindent 50. Метод конечных разностей для уравнения Пуассона.\\
\noindent 51. Спектральный признак устойчивости и примеры его применения для аппроксимаций гиперболического уравнения.\\
\noindent 52. Принцип замороженных коэффициентов.\\
\noindent 53. Исследование устойчивости простейших схем для уравнения теплопроводности в равномерной метрике.\\
\noindent 54. Исследование устойчивости схемы с весами для уравнения теплопроводности в интегральной метрике.\\
}

\section {Погрешность метода и вычислительная погрешность. Пример неустойчивого алгоритма.}
    \hyperlink {lects.1}{Лекции} \\
    \textbf{Описание численного метода:}\\
    Постановка задачи $\rightarrow$ Приближенный метод решения $\rightarrow$ Оценка погрешности (\textit{погрешность метода}) $\rightarrow$ Оценка погрешности с учетом округлений (\textit{влияние вычислительной погрешности})  

	\begin{example}
    	Пример неустойчивого алгоритма \\
    	\hyperlink {lects.14}{Лекции}\\
    	Пусть требуется вычислить последовательность интегралов:
    	$$
    	    \int_0^{2\pi}{x^n e^{x-1}dx}, n = 1,2,3,...,N.
    	$$
    	Для построения численного алгоритма проведем интегрирование по частям:
    	$$
    	\begin{aligned}
    	    & I_n = \int_0^{2\pi}{x^n d(e^{x-1})} = x^n e^{x-1} \big|_0^1 - \int_0^{2\pi}{n x^{n-1} e^{x-1}dx} = 1 - n 	I_{n-1} \\
        	& I_1 = \frac{1}{e}
    	\end{aligned}
    	$$
    	Легко заметить, что при отсутствии ошибок округления погрешность метода равна нулю (точный метод!). Что будет при реальных вычислениях? Рассмотрим ситуацию, когда погрешность возникает только вследствие определения величины $I_n$. Введем обозначение для ошибки $z_n = I_n - I_n^*$. Тогда
    	$$
    	\begin{aligned}
    	    & I_n^* = 1 - n I_{n-1}^* \\
        	& z_n = - n z_{n-1} = n! (-1)^{n+1} z_1
    	\end{aligned}
    	$$
    	Погрешность очень быстро (факториально!) растёт. Очень скоро это приведет к сильному искажению искомого результата.
	\end{example}

\section {Алгебраическая интерполяция. Многочлен Лагранжа.}
	\hyperlink {lects.15}{Лекции}\\
	Отрезок $[a,b]$ разбит на $n$ узлов $a = x_1 < x_2 < ... < x_n = b$ и в них заданы $f_i$ - значения функции $f$ в $x_i$. Требуется найти многочлен $L_{n-1}(x)$ степени $n - 1$ чтоб $L_{n - 1}(x_i) = f_i$.

	\textbf{Многочлен Лагранжа $L_{n - 1}(x)$}
	$$
		\begin {array}{lr}
		L_{n - 1}(x) = \sum\limits_{i = 1}^{n} f_i \Phi_i (x), & \Phi_i(x) = \prod\limits_{j = 1, j\ne i}^{n} \frac{x-x_j}{x_i - x_j} \\
		\end {array}
	$$

	\begin{state}
		(\hyperlink {lects.16}{Лекции})Пусть n-я производная функции $f(x)$ непрерывна на $[a,b]$, тогда $\forall x \in [a,b] \ \  \exists \xi \in [a,b]$, что справедливо
		$$
			\begin{array}{lr}
			f(x) - L_{n-1}(x) = \frac {f^{(n)}(\xi)}{n!} \omega_n(x), & \omega_n(x) = \prod\limits_{i - 1}^{n}(x-x_i)
			\end{array}
		$$
	\end{state}
	Следствие:
	$$
		||f(x) - L_{n-1}(x) || \le \frac{||f^{(n)}(x)||}{n!} ||\omega_n||
	$$
	$$
		||g(x)|| = \underset{x\in [a,b]}{sup} |g(x)|
	$$


\section {Константа Лебега интерполяционного процесса для равноотстоящих узлов.}
	\hyperlink {lects.17}{Лекции}\\
	\textbf{Константа Лебега интерполяционного процесса}(\hyperlink {lects.17}{Подробно})
	$$
		\begin{array}{lr}
		\lambda_n = \underset{x\in [a,b]}{max} \sum\limits_{i = 1}^n |\Phi_i(x)|, & \Phi_i(x) = \prod\limits_{j = 1, j\ne i}^{n} \frac{x-x_j}{x_i - x_j} \\
		\end{array}
	$$
	
	\begin{state}
	$\lambda_n$ не зависит от длины отрезка интерполяции (\hyperlink {lects.17}{Утверждение 1})
	\end{state}
	
	Оценка снизу  для $\lambda_n (n \ge 2)$ (\hyperlink {lects.17}{Утверждение 2})
	$$
		\lambda \ge K \frac {2^n}{n^{3/2}}, 
	$$ 
	где $K$ не зависит от $n$. \\
	

\section {Многочлены Чебышёва и их свойства.}
	\hyperlink {lects.18}{Лекции}\\
	\textbf{Способы определения}
	\begin{enumerate}
		\item Рекуррентно 
			  $$
			  	\begin{array}{lcr}
			  		T_0(x) = 1, & T_1(x) = x, & T_{n+1}(x) = 2xT_n(x) - T_{n-1}(x)
			  	\end{array}
			  $$
		\item Тригонометрически $x\in[-1,1]$
			  $$
			  	T_n(x) = cos(n \ arccos(x))
			  $$
		\item Разностное уравнение
			  $$
			  	T_n(x) = \frac{1}{2}\left( \left( x + \sqrt{x^2 - 1} \right)^n + \left( x - \sqrt{x^2 - 1} \right)^n \right)
			  $$
	\end{enumerate}
	\textbf{Свойства}
	\begin{enumerate}
		\item $|T_n(x)| \le 1$ при $x \in [-1,1]$
		\item $T_n(-x) = (-1)^nT_n(x)$
		\item Коэффициент при старшем члене равен $2^{n - 1}$
		\item Все нули находятся на $[-1,1]$ в точках
			$$
				x_k = cos \frac{\pi (2k -1)}{2n} \ \ \ k = 1, ... , n
			$$
		\item Экстремумов на $[-1,1]$ $n+1$ штук в точках
			$$
				x_m = cos \frac{\pi m}{n} \ \ \ m = 0, ... , n
			$$ 
		\item Отображение на отрезок 
			$$
				T_n^{[a,b]} (x) = (b - a)^n 2^{1-2n} T_n \left( \frac{2x - (b+a)}{b-a} \right)
			$$
	\end{enumerate}

	Приведенный многочлен Чебышёва (со старшим коэффициентом 1)
	$$
		\bar {T_n} = 2^{1 - n}T_n
	$$
	
	\begin{state} (\hyperlink {lects.19}{Утверждение 3})
		Приведенный многочлен Чебышёва на $[-1,1]$ наименее отклоняется от нуля. То есть 
		$$
			\underset{[-1,1]}{max}|P_n(x)| \ge \underset{[-1,1]}{max} |\bar{T_n(x)}| = 2^{1-n},
		$$
		где $P_n(x)$ - любой многочлен степени $n$ с коэффициентом 1 при $n$-ой степени.
	\end{state}

	При фиксированном $n$ выбор корней $T_n(x)$ в качестве узлов для многочлена лагранжа является оптимальным.
	(\hyperlink {lects.20}{Минимизация оценки погрешности})

	

\section {Интерполяционные сплайны. Конструкция и обоснование кубического сплайна.}
	\hyperlink {lects.22}{Лекции}\\
	$a = x_0 < x_1 < ... < x_n = b$\\
	$P_m(x)$ - множество всех многочленов, степени не выше $m$.
	\begin{defn}
		Полиномиальный и интерполяционный сплайн \hyperlink {lects.22}{Лекции}
	\end{defn}

	\begin{defn}
		Естественный сплайн \hyperlink {lects.23}{Лекции, 2ой абзац} ($M_i$ - значения второй производной сплайна в $x_i$)
	\end{defn}

\section {Понятие об аппроксимационных сплайнах.}
	\hyperlink {lects.25}{Лекции}\\
	В отличии от интерполяционных не требуют пересчета всех коэффициентов при изменении одного (нескольких) значений $f_i$. Потому что строятся локально на каждом $[x_{i-1}, x_i]$ и зависят лишь от некотрого постоянного числа соседних $f_i$ (1, 2, 3 - обычно немного).
	
	Построение аппроксимационного сплайна 3ей степени (\hyperlink {lects.25}{Лекции}).
	
	Оценки для второй и первой производной и для разности (для сплайна 3ей степени) (\hyperlink {lects.27}{Лекции}):
	$$
		f(x) \in C^2[0,1], \ \ \ \ \ |f''(x)|_{[0,1]} < A_2
	$$
	\begin{itemize}
		\item Для второй производной $|B''_2(x_k)| \le A_2$
		\item Для первой производной $\underset{x}{max}|f'(x)-B'_2(x)| \le C_1 h A_2 \ \ \ \ \ \  \ C_1 = \frac{5}{2}$
		\item Просто для разности $\underset{x}{max}|f(x)-B_2(x)| \le C_0 A_2 h^2$
			
	\end{itemize}
	
	
	

\section {Наилучшее приближение в линейном нормированном пространстве.}
	\hyperlink {lects.28}{Лекции}\\
	\begin{defn}
	Задан элемент $f$ линейного нормированного пространства $\mathcal{L}$. Хотим найти его наилучшее приближение комбинацией заданных независимых элементов $g_1, ..., g_n \in \mathcal{L}$. Т.е. найти $x = \sum\limits_{j = 1}^{n}c_j^0g_j$ такой, что
	$$
		||f - x|| = ||f - \sum\limits_{j = 1}^{n}c_j^0g_j|| = \underset{c_1,...,c_n}{inf} ||f - \sum\limits_{j = 1}^{n}c_jg_j||
	$$
	\end{defn}

	Всегда существует, но не обязательно единственный. (\hyperlink {lects.28}{утв 1})
	
	\begin{defn}  
		Пространство $\mathcal{L}$ строго нормированно, если из условия
		$$
			||f+g|| = ||f||+||g|| \ \ \ \ \ \ \ \ \ \ ||f||,||g|| \ne 0
		$$
		следует $f = \alpha g, \alpha \ne 0$.
	\end{defn}

	В случае строго нормированного элемент наилучшего приближения единственный (\hyperlink {lects.29}{утв 2})

\section {Наилучшее приближение в гильбертовом пространстве.}
	\hyperlink {lects.29}{Лекции}\\
	Т.е. есть скалярное произведение $(x,y)$ и норма $||x||=\sqrt{(x,x)}$. \\
	Гильбертово пространство - строго нормированное (\hyperlink {lects.29}{утв 3}) \\
	
	Поиск наилучшего приближения - решение СЛАУ. (всегда имеет единственное решение \hyperlink {lects.30}{утв 4})
	$$
		Ac = b, \ \ \ \ \ \ a_{ij} = (g_i, g_j) \ \ \ b_i = (f, g_i)
	$$
	
	Пример, приводящий к матрице Гильберта (\hyperlink {lects.31}{Лекции}):
	
	$\mathcal{L}$ - пространство вещественных функций с ограниченным интегралом $\int\limits_0^1 f^2(x)dx < \inf $ и скалярным произведением $(f,g) = \int\limits_0^1 f(x)g(x)dx$. В качестве $g_1, ..., g_n$ выберем систему многочленов $1, x, ..., x^{n-1}$. Тогда элементы матрицы $a_{ij} = (x^{i-1},x^{j-1}) = \frac{1}{i+j-1}$. Это матрица Гильберта, на ней решения находятся с большой погрешностью из-за влияния машинной точности. 

\section {Дискретное преобразование Фурье. Идея быстрого дискретного преобразования Фурье.}
	\hyperlink {lects.32}{Лекции}\\

\section {Наилучшее равномерное приближение многочленами.}
	\hyperlink {lects.35}{Лекции}\\

\section {Квадратурные формулы интерполяционного типа.}
	\hyperlink {lects.37}{Лекции}\\

\section {Ортотональные многочлены и квадратуры Гаусса.}
	\hyperlink {lects.40}{Лекции}\\

\section {Составные квадратурные формулы. Правило Рунге для оценки погрешности.}
	\hyperlink {lects.44}{Лекции}\\

\section {Основные приёмы для вычисления нерегулярных интегралов.}
	\hyperlink {lects.45}{Лекции}\\

\section {Метод прогонки для решения трёхдиагональных систем. Корректность и устойчивость метода прогонки.}
	\hyperlink {lects.48}{Лекции}\\

\section {Прямые методы решения систем линейных уравнений. Методы Гаусса и Холецкого.}
	\hyperlink {lects.51}{Лекции}\\

\section {Прямые методы решения систем линейных уравнений. Методы отражений и вращений.}
	\hyperlink {lects.54}{Лекции}\\

\section {Число обусловленности. Неравенства для ошибки и невязки.}
	\hyperlink {lects.56}{Лекции}\\

\section {Метод простой итерации решения систем линейных уравнений.}
	\hyperlink {lects.58}{Лекции}\\
	Дана СЛАУ $Ax = b$. Преобразуем её к виду $x = Gx + c$. Если решение этой системы находится как предел последовательности
	$$
	    x^{k+1} = Gx^{k} + c,
	$$
	то такой процесс называется {\it методом простой итерации} (далее МПИ). $G$ - {\it оператор перехода}.\\
	Для систем со знакоопредленными матрицами МПИ обычно строится в виде
	$$
	    \frac{x^{k+1} - x^{k}}{\tau} + Ax^{k} = b,
	$$
	т.е. $G = I - \tau A, \,\, c = \tau b$. $\tau$ - итерационный параметр.
	\begin{state} (\hyperlink {lects.58}{Достаточное условие сходимости МПИ})\\
	Если $||G|| < 1$, то система имеет единственное решение и итерационный процесс сходится
	к решению со скоростью геометрической прогрессии.
	\end{state}
    \begin{state} (\hyperlink {lects.59}{Критерий сходимости МПИ})\\
    Пусть система имеет единственное решение. Итерационный процесс сходится к решению системы тогда и только тогда, когда все собственные значения матрицы $G$ по модулю меньше 1. ($|\lambda_{G}| < 1$)
    \end{state}
    Пусть $A = A^* > 0$. Б.о.о. можем считать, что $\lambda(A) \in [m, M],\,\, m > 0$.
    Метод $ \frac{x^{k+1} - x^{k}}{\tau} + Ax^{k} = b$ сходится при $0 < \tau < \frac{2}{M}$.

\newpage
\section {Оптимальный одношаговый итерационный метод.}
	\hyperlink {lects.60}{Лекции}\\
	Хотим выяснить, при каком $\tau$ сходимость метода
	$\frac{x^{k+1} - x^{k}}{\tau} + Ax^{k} = b,$ будет наилучшей.
	\begin{state} (\hyperlink {lects.60}{Оптимальный $\tau$})\\
	При условии $A = A^T > 0, \,\, \lambda(A) \in [m, M]$ оптимальное значение
	$$\tau_0 = \frac{2}{m+M}$$
	При этом имеет место скорость сходимости $q_0 = \frac{M-m}{M+m} < 1$ (в норме 2).
	\end{state}

\section {Оптимальный циклический итерационный метод.}
	\hyperlink {lects.61}{Лекции}\\
	Рассмотрим следующий алгоритм с переменным итерационным параметром:
	$$
	    \frac{x^{k+1} - x^{k}}{\tau_{k+1}} + Ax^{k} = b.
	$$
	Будем считать, что допускается изменение параметра $\tau$ в зависимости от номера итерации циклическим образом с периодом $N$.
	\begin{state} (\hyperlink {lects.61}{Оптимальный $\tau_{k}$})\\
	При условии $A = A^T > 0, \,\, \lambda(A) \in [m, M]$ оптимальные значения $\tau_k$
	равны обратным величинам корней многочлена Чебышева степени $N$ на отрезке $[m, M]$:
	$$
	\tau_k^{-1} = \frac{M+m}{2} + \frac{M-m}{2}\cos\frac{\pi(2k-1)}{2N}, \,\, k = 1,...,N.
	$$
	При этом имеет место скорость сходимости
	$q_1 = \frac{\sqrt{M}-\sqrt{m}}{\sqrt{M}+\sqrt{m}}$ (в норме 2).
	\end{state}
	Здесь появляется важный аспект {\bf упорядочивания шагов}. В каком порядке брать $\tau_k$?
	Ответ: \hyperlink {lects.62}{процедура упорядочивания шагов}.

\section {Обобщённый метод простой итерации.}
	\hyperlink {lects.63}{Лекции}\\

\section {Методы Якоби и Гаусса -- Зейделя.}
	\hyperlink {lects.65}{Лекции}\\

\section {Метод верхней релаксации.}
	\hyperlink {lects.67}{Лекции}\\

\section {Метод наискорейшего градиентного спуска.}
	\hyperlink {lects.68}{Лекции}\\

\section {Линейная задача наименьших квадратов. Метод нормального уравнения.}
	\hyperlink {lects.71}{Лекции}\\

\section {Линейная задача наименьших квадратов. Методы QR-разложения и сингулярного разложения.}
	\hyperlink {lects.72}{Лекции}\\

\section {Общая идея и примеры проекционных методов.}
	\hyperlink {lects.74}{Лекции}\\

\section {Пространства Крылова. Понятие о методе сопряженных градиентов.}
	\hyperlink {lects.74}{Лекции}\\

\section {Частичная проблема собственных значений.}
	\hyperlink {lects.78}{Лекции}\\
	$A$ \--- матрица $n*n$. Ищем собственный вектор $x \ne 0$ и собственное значение $\lambda$ : $Ax = \lambda x$.
	\textbf{Степенной метод вычисления максимального по модулю с.з.}:\\
	\begin{center}
	\label{step_met}
	$x^{k+1} = Ax^k$,  $\lambda^{(k)} = \frac{(x^{k+1}, x^k)}{\|x^k\|^2_2}$, $x^k \ne 0$,  $k=0,1,2...$.
	\end{center}
	\textbf{Утверждение 1}\\
	Пусть $A$ \--- матрица простой структуры (базисные векторы $\{e_i\}^n_1$ - образуют простой базис в $C^n$). Пусть далее $|\lambda_1| > |\lambda_2| \geq |\lambda_3| \geq ... \geq |\lambda_n|$ и $L=span\{e_2,e_3,...,e_n\}$. Тогда для степенного метода (\ref{step_met}), при условии $x^0 \notin L$ справедлива оценка $\lambda^{(k)} = \lambda_1 + O(|\lambda_2/\lambda_1|^k)$.
	
	$\square$ Кратко.\\
	Разложим начальное приближение по собственным векторам, оттуда получим такие же разложения для $x^k, x^{k+1}$. Оцениваем рост их скалярного произведения: $(x^{k+1}, x^k) = c^2_1 \lambda^{2k+1}_1 (e_1, e_1) + 0(|\lambda^{k+1}_1\lambda^k_2|)$.
	Рассматриваем величину $\lambda^{(k)}$, как отношение этой штуки к квадрату нормы $x^k$,  получаем $\lambda_1 + O(|\lambda2/\lambda_1|^k)$. А если матрица симметричная, то можно, учитывая ортогональность с.в. получить степень $2k$. 
	$\square$
	
	
	Для поиска наименьшего с.з. матрицы можно использовать \textbf{метод обратной итерации}. (степенной метод для $A^{-1}$):\\
	\begin{center}
	$x^k := x^k / \|x^k\|_2, Ax^{k+1} = x^k, \lambda^{(k)} = \frac{(x^k, x^{k+1})}{(x^{k+1}, x^{k+1})}$
	\end{center}
	
	\textbf{Замечание}: На каждом шаге придется решать систему: $Ax^{k+1} = x^k$.
\\
Если у нас вырожденная или близкая к тому матрица, то можно использовать эти методы со сдвигом, т.е. применить их к матрице $A-cE$, с достаточно малым $c$.  Если известно приближение к собственному значению $\lambda$ \--- $\overline{\lambda}$, то метод простой итерации с $c = \overline{\lambda}$ - очень быстро сходится. Также, в качестве сдвига $c$ можно взять \textbf{отношение Рэлея}: $R_A(x) = \frac{(Ax, x)}{(x, x)}$, что приводит к кубической сходимости.
	
	

\section {Полная проблема собственных значений. QR-алгоритм.}
	\hyperlink {lects.79}{Лекции}\\

\section {Метод простой итерации для нелинейных уравнений.}
	\hyperlink {lects.82}{Лекции}\\

\section {Метод Ньютона.}
	\hyperlink {lects.83}{Лекции}\\

\section {Явный метод Эйлера для обыкновенных дифференциальных уравнений (ОДУ). Устойчивость. Локальная и глобальная ошибки.}
	\hyperlink {lects.87}{Лекции}\\

\section {Явные методы Рунге -- Кутты.}
	\hyperlink {lects.89}{Лекции}\\

\section {Неявные одношаговые методы решения ОДУ.}
	\hyperlink {lects.91}{Лекции}\\

\section {Многошаговые методы решения ОДУ.}
	\hyperlink {lects.92}{Лекции}\\

\section {Основы метода конечных элементов: вариационная постановка задачи, метод Ритца, базисные функции.}
	\hyperlink {lects.97}{Лекции}\\

\section {Оценка точности приближения кусочно -- линейными функциями.}
	\hyperlink {lects.102}{Лекции}\\

\section {Проекционная теорема в методе конечных элементов.}
	\hyperlink {lects.103}{Лекции}\\

\section {Система уравнений в методе конечных элементов.}
	\hyperlink {lects.106}{Лекции}\\

\section {Решение модельной задачи методом Фурье.}
	\hyperlink {lects.108}{Лекции}\\

\section {Исследование устойчивости модельной задачи методом Фурье.}
	\hyperlink {lects.111}{Лекции}\\

\section {Метод стрельбы для решения трехдиагональных систем.}
	\hyperlink {lects.112}{Лекции}\\

\section {Пример аппроксимации уравнения и краевых условий.}
	\hyperlink {lects.115}{Лекции}\\

\section {Определения аппроксимации и устойчивости.}
	\hyperlink {lects.118}{Лекции}\\

\section {Определение сходимости. Теорема А.Ф.Филиппова.}
	\hyperlink {lects.120}{Лекции}\\

\section {Интегро -- интерполяционный метод.}
	\hyperlink {lects.121}{Лекции}\\

\section {Исследование устойчивости методом априорных оценок.}
	\hyperlink {lects.125}{Лекции}\\

\section {Метод конечных разностей для уравнения Пуассона.}
	\hyperlink {lects.128}{Лекции}\\

\section {Спектральный признак устойчивости и примеры его применения для аппроксимаций гиперболического уравнения.}
	\hyperlink {lects.130}{Лекции}\\

\section {Принцип замороженных коэффициентов.}
	\hyperlink {lects.132}{Лекции}\\

\section {Исследование устойчивости простейших схем для уравнения теплопроводности в равномерной метрике.}
	\hyperlink {lects.134}{Лекции}\\

\section {Исследование устойчивости схемы с весами для уравнения теплопроводности в интегральной метрике.}
	\hyperlink {lects.136}{Лекции}\\




\includepdf[pages=-, link, linkname = lects]{ch-m_II-20.pdf}
\end{document}
